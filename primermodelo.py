# -*- coding: utf-8 -*-
"""PrimerModelo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zl1nYP8X_fVho8HsjDAjqJbY9PP7KAkV
"""

!pip install 'neptune-contrib[monitoring]>=0.24.9'

!pip install -U xgboost

import neptune
import pandas as pd
import xgboost as xgb
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split

# here you import `neptune_calback` that does the magic (the open source magic :)
from neptunecontrib.monitoring.xgboost_monitor import neptune_callback
from sklearn import preprocessing
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score

neptune.init('shared/XGBoost-integration',
             api_token='ANONYMOUS')

df_Base_Datos = pd.read_csv("Archivo_Latitud_Limpia.csv", encoding = 'latin-1')
X = pd.read_csv('Archivo_Latitud_Limpia.csv',usecols = [i for i in range(17)], encoding = 'latin-1')
lbl = preprocessing.LabelEncoder()
X['Año/Mes'] = lbl.fit_transform(X['Año/Mes'].astype(str))
X['Piso'] = lbl.fit_transform(X['Piso'].astype(str))
X['Categoría del bien'] = lbl.fit_transform(X['Categoría del bien'].astype(str))
X['Posición'] = lbl.fit_transform(X['Posición'].astype(str))
X['Estado de conservación'] = lbl.fit_transform(X['Estado de conservación'].astype(str))
X['Método Representado'] = lbl.fit_transform(X['Método Representado'].astype(str))
X['Área Terreno'] = lbl.fit_transform(X['Área Terreno'].astype(str))
X['Área Construcción'] = lbl.fit_transform(X['Área Construcción'].astype(str))
#Y['Año/Mes'] = lbl.fit_transform(X['Año/Mes'].astype(str))

y = pd.read_csv('Archivo_Latitud_Limpia.csv', usecols=["Valor comercial (USD)"], encoding = 'latin-1')
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
print(y_train.dtypes)



from pandas.io.formats.printing import enable_data_resource_formatter
#XGboost Sets
dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)
dtest = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)

params = {'max_depth': 50,
          'eta': 0.75,
          'gamma': 0.001,
          'silent': 1,
          'subsample': 1,
          'lambda': 1,
          'alpha': 0.35,
          'objective': 'reg:linear',
          'eval_metric': ['mae', 'rmse']}
watchlist = [(dtest, 'eval'), (dtrain, 'train')]
num_round = 100

#neptune.create_experiment(name='xgb', tags=['train'], params=params)
bst = xgb.train(params, dtrain, num_round, watchlist)

y_pred = bst.predict(dtest)
print(len(y_pred))
print(y_test)
print(len(y_test))
print(y_pred)

#print(type(y_test.to_numpy()))
#y_test=y_test.to_numpy()
print(type(y_test))
print(roc_auc_score(y_test, y_pred), multi_class='ovr')

